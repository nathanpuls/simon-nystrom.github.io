<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><link href="https://use.fontawesome.com/releases/v5.15.1/css/svg-with-js.css" rel="stylesheet"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/atom-one-dark-reasonable.min.css"/><link rel="icon" type="image/png" href="/favicon.png"/><meta charSet="utf-8"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><title>Web scraping with Python</title><meta name="description" content="Learn how to scrape web sites to access information programmatically using Python3, BeautifulSoup and Requests."/><link rel="preload" href="/_next/static/css/1a74711cce26b49facf0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/1a74711cce26b49facf0.css" data-n-g=""/><noscript data-n-css="true"></noscript><link rel="preload" href="/_next/static/chunks/main-652e3d69fea5bda26a4d.js" as="script"/><link rel="preload" href="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework.93a4db703368d9b8f53e.js" as="script"/><link rel="preload" href="/_next/static/chunks/a9a7754c.c97121148934262ae49b.js" as="script"/><link rel="preload" href="/_next/static/chunks/99f422a92ff7083adb8a7d840734144fa7589f68.f6d970403bd2fa4c2639.js" as="script"/><link rel="preload" href="/_next/static/chunks/99ce5ded03d7686e4bf70ff5f951df53c1ed333a.b57b3b603baeb24450d4.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-24c8b9694b01810a31ee.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/blog/%5Bslug%5D-a9359318c29489431ba1.js" as="script"/><style data-styled="" data-styled-version="5.2.1">.gCPmgg{max-width:48em;padding-left:2em;padding-right:2em;padding-bottom:10px;box-sizing:border-box;position:absolute;left:0;right:0;bottom:0;margin:auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
data-styled.g1[id="Footer__FooterWrapper-sc-1r5v4in-0"]{content:"gCPmgg,"}/*!sc*/
.ffSMEu{font-size:0.7em;}/*!sc*/
data-styled.g2[id="Footer__Copyright-sc-1r5v4in-1"]{content:"ffSMEu,"}/*!sc*/
.dlVATn{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;max-height:50px;}/*!sc*/
data-styled.g3[id="Footer__Social-sc-1r5v4in-2"]{content:"dlVATn,"}/*!sc*/
.iZJeFu svg{-webkit-transition:color 0.2s ease;transition:color 0.2s ease;color:white;}/*!sc*/
.iZJeFu:hover svg{cursor:pointer;color:#83a0e1;}/*!sc*/
data-styled.g4[id="Footer__Icon-sc-1r5v4in-3"]{content:"iZJeFu,"}/*!sc*/
.btlfRb{font-size:1.4em;margin-right:14px;}/*!sc*/
.btlfRb:last-child{margin-right:0;}/*!sc*/
data-styled.g5[id="Footer__A-sc-1r5v4in-4"]{content:"btlfRb,"}/*!sc*/
.DhNpn{border-bottom:2px solid #262e40;margin-top:-2px;}/*!sc*/
data-styled.g6[id="NavBar__NavWrapper-sc-3ha8w-0"]{content:"DhNpn,"}/*!sc*/
.dWsLiR{max-width:48em;margin:0 auto;font-weight:300;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-left:2em;padding-right:2em;}/*!sc*/
data-styled.g7[id="NavBar__Nav-sc-3ha8w-1"]{content:"dWsLiR,"}/*!sc*/
.jLOfbH{color:inherit;-webkit-text-decoration:none;text-decoration:none;display:block;padding:1em 0.8em;position:relative;border-bottom:2px solid #262e40;top:2px;-webkit-transition:border-bottom 0.2s ease;transition:border-bottom 0.2s ease;border-bottom:2px solid #262e40;}/*!sc*/
.jLOfbH:first-child{padding:1em 0em;}/*!sc*/
.jLOfbH:hover{cursor:pointer;border-bottom:2px solid #83a0e1;}/*!sc*/
.cYWqKS{color:inherit;-webkit-text-decoration:none;text-decoration:none;display:block;padding:1em 0.8em;position:relative;border-bottom:2px solid #262e40;top:2px;-webkit-transition:border-bottom 0.2s ease;transition:border-bottom 0.2s ease;border-bottom:2px solid #83a0e1;}/*!sc*/
.cYWqKS:first-child{padding:1em 0em;}/*!sc*/
.cYWqKS:hover{cursor:pointer;border-bottom:2px solid #83a0e1;}/*!sc*/
data-styled.g8[id="NavBar__A-sc-3ha8w-2"]{content:"jLOfbH,cYWqKS,"}/*!sc*/
.dGychE{position:relative;max-width:48em;padding:2em;padding-bottom:4.5em;margin:0 auto;box-sizing:border-box;min-height:100%;}/*!sc*/
data-styled.g9[id="_app__Content-sc-1bgbx94-0"]{content:"dGychE,"}/*!sc*/
.dGuGHk{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;font-size:0.73em;padding:2px 6px;background-color:#262e40;margin:2px;border-radius:4px;}/*!sc*/
data-styled.g10[id="Tag__TagWrapper-yn0xte-0"]{content:"dGuGHk,"}/*!sc*/
.gKGqWB{padding:0.8em;padding-left:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
data-styled.g11[id="slug__Meta-sc-1tgsv9k-0"]{content:"gKGqWB,"}/*!sc*/
.kJfTuM{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;}/*!sc*/
data-styled.g12[id="slug__Tags-sc-1tgsv9k-1"]{content:"kJfTuM,"}/*!sc*/
</style></head><body><div id="__next"><div><div class="NavBar__NavWrapper-sc-3ha8w-0 DhNpn"><nav class="NavBar__Nav-sc-3ha8w-1 dWsLiR"><a href="/" class="NavBar__A-sc-3ha8w-2 jLOfbH">home</a><a href="/blog" class="NavBar__A-sc-3ha8w-2 cYWqKS">blog</a></nav></div><main class="_app__Content-sc-1bgbx94-0 dGychE"><h1 style="font-size:2.2em">Web scraping with Python</h1><div class="slug__Meta-sc-1tgsv9k-0 gKGqWB"><h5 class="gray">2020-11-01</h5><div class="gray">ãƒ»</div><div class="slug__Tags-sc-1tgsv9k-1 kJfTuM"><div class="Tag__TagWrapper-yn0xte-0 dGuGHk">python</div><div class="Tag__TagWrapper-yn0xte-0 dGuGHk">web-scraping</div><div class="Tag__TagWrapper-yn0xte-0 dGuGHk">requests</div><div class="Tag__TagWrapper-yn0xte-0 dGuGHk">tutorial</div><div class="Tag__TagWrapper-yn0xte-0 dGuGHk">beautifulsoup</div></div></div><article class="blog-post-content"><p>Sometimes you want to access data on the web that isn&#39;t easily available through an API. For that, web scraping is a viable alternative. Web scraping is in essence a way to programmatically visit a web site as if you were a browser and fetch the data that way. This tutorial post will guide you through the process of web scraping using Python3, and two libraries <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup</a> and <a href="https://requests.readthedocs.io/en/master/">Requests</a>. As an example, we will build a command line application to search and print ratings for movies and TV shows on IMDB.</p>
<hr>
<h1 id="project-setup">Project setup</h1>
<p>To follow along with the tutorial you will need to have the following:</p>
<ul>
<li><a href="https://www.python.org/downloads/">Python</a> installed</li>
<li>Some basic knowledge of Python and some basic HTML/CSS knowledge</li>
</ul>
<p>Alternatively you can check out <a href="https://newcurrent.se/blog/containerized-development-environment">my blog post for using dev containers</a> and follow that guide but select the <code>Python 3</code> container spec when creating the dev container. If you can&#39;t get the dev container way to work, you can refer to the <a href="https://github.com/simon-nystrom/simple-web-scrape">repository for this blog post</a>.</p>
<p>Let&#39;s begin by creating a folder for our project and installing the required dependencies:</p>
<pre><div class="copy-me" onclick="copyCode(this)">Copy</div><code>mkdir web-scrape
<span class="hljs-built_in">cd</span> web-scrape
pip3 install beautifulsoup4 requests</code></pre><ul>
<li><code>beautifulsoup4</code> lets us easily access DOM elements programmatically</li>
<li><code>requests</code> gives us a nice and easy to use interface to make HTTP requests</li>
</ul>
<hr>
<h1 id="researching-the-applications-lifecycle">Researching the application&#39;s lifecycle</h1>
<p>As stated in the introduction, we&#39;re going to focus on searching on IMDB showing the rating for some selected title. Our first step should be to do these steps in a browser and see what it looks like there.</p>
<p>Visit <a href="http://www.imdb.com">www.imdb.com</a> in your browser and search for a movie of your choice. I searched for <em>Jurassic Park</em>, you should be greeted with something like the following image:</p>
<p><img src="/images/imdb/jurassic_park_search_res.png" alt="Jurassic Park search result on IMDB"></p>
<p>Once you&#39;re on this page, inspect one of the rows in the <em>&quot;Titles&quot;</em> table by right clicking and pressing <em>&quot;Inspect element&quot;</em>, this varies from browser to browser but in Firefox it looks like this:</p>
<p><img src="/images/imdb/inspect_element.png" alt="Inspect element"></p>
<p>You might also have noticed that something opened up at the bottom of your browser, that section is commonly referred to as the dev tools. We&#39;ll be using that now to figure out the structure of the data that we&#39;re after. At the time of writing this, it looks like this:</p>
<p><img src="/images/imdb/dev_tools.png" alt="Dev tools open"></p>
<p>What&#39;s displayed here is the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model/Introduction">DOM</a> structure. The highlighted row here is what I selected when taking the <em>&quot;Inspect element&quot;</em> action earlier. This shows us how all the HTML nodes relate to each other and where in the DOM the data we&#39;re after is located. Since we want to be able to list these results in our application, we need to be able to present these search results.</p>
<p>We can see that the data we&#39;re interested in is located inside the <code>&lt;td&gt;</code> element with the class <code>result_text</code>, the name of the title is wrapped in an <code>&lt;a&gt;</code> element with the <code>href</code> holding the relative link to the title. This is all the data we need from this page.</p>
<p>Let&#39;s follow the link to this title to see what the next page we need to tackle looks like, click the link to one of the search results and you should end up on the page for the movie/show you picked:</p>
<p><img src="/images/imdb/jurassic_park.png" alt="Jurassic park"></p>
<p>When on this page, let&#39;s repeat the step and <em>&quot;Inspect element&quot;</em> on the rating display:</p>
<p><img src="/images/imdb/inspect_element_2.png" alt="Inspect rating element">
<img src="/images/imdb/dev_tools_2.png" alt="Dev tools on inspect rating element"></p>
<p>Here we can see that for this page the data we&#39;re interested in is located inside a <code>span</code> element wrapped by a <code>strong</code> element that is in turn wrapped by a <code>div</code> element with the class <code>ratingValue</code>.</p>
<p>Now that we have gathered all the information we need for our app, let&#39;s proceed to the coding part.</p>
<hr>
<h1 id="searching-on-imdb-and-listing-the-titles">Searching on IMDB and listing the titles</h1>
<p>Create a file <code>scrape.py</code>, this will be our only file for this project. In it we will begin by importing the required dependencies and adding search functionality:</p>
<pre><div class="copy-me" onclick="copyCode(this)">Copy</div><code><span class="hljs-comment"># scrape.py</span>
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search</span>(<span class="hljs-params">search_term</span>):</span>
    <span class="hljs-comment"># Make the search request to IMDB</span>
    response = requests.get(<span class="hljs-string">f&quot;https://www.imdb.com/find?q=<span class="hljs-subst">{search_term}</span>&quot;</span>)
    html = response.text
    soup = BeautifulSoup(html, <span class="hljs-string">&quot;html.parser&quot;</span>)
    <span class="hljs-comment"># Find the table with the class findList</span>
    table = soup.find(<span class="hljs-string">&quot;table&quot;</span>, {<span class="hljs-string">&quot;class&quot;</span>: <span class="hljs-string">&quot;findList&quot;</span>})
    <span class="hljs-comment"># Use CSS selector syntax to get all td elements from the table with the class result_text</span>
    rows = table.select(<span class="hljs-string">&quot;tr td.result_text&quot;</span>)
    <span class="hljs-comment"># Construct a list with the search results, store the title and the href in dicts</span>
    <span class="hljs-keyword">return</span> [{<span class="hljs-string">&quot;title&quot;</span>: row.get_text().strip(), <span class="hljs-string">&quot;href&quot;</span>: row.a[<span class="hljs-string">&#x27;href&#x27;</span>]} <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> rows]</code></pre><p>Let&#39;s add another function to this file where we&#39;ll place our user interaction code:</p>
<pre><div class="copy-me" onclick="copyCode(this)">Copy</div><code><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span>():</span>
    search_term = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Search IMDB: &quot;</span>)
    results = search(search_term)
    num_results = <span class="hljs-built_in">len</span>(results)
    print(<span class="hljs-string">f&quot;Found <span class="hljs-subst">{num_results}</span> results:&quot;</span>)
    <span class="hljs-comment"># Use built-in function enumerate to access the index variable i</span>
    <span class="hljs-keyword">for</span> i, result <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(results):
        print(<span class="hljs-string">f&quot;(<span class="hljs-subst">{i+<span class="hljs-number">1</span>}</span>) <span class="hljs-subst">{result[<span class="hljs-string">&#x27;title&#x27;</span>]}</span>&quot;</span>)

<span class="hljs-comment"># Don&#x27;t forget this line! We have to call the run function or nothing will happen when we run our program.</span>
run()</code></pre><p>Save the file and we&#39;re ready to try our app to see what it looks like right now, run it by going to the terminal and running:</p>
<pre><div class="copy-me" onclick="copyCode(this)">Copy</div><code>python3 scrape.py</code></pre><p>Enter a search term and something similar should show up:</p>
<p><img src="/images/imdb/in_app_search_res.png" alt="in app search results"></p>
<p>You might notice that selecting a result does nothing at the moment, and that&#39;s cause we only implemented half the logic. It&#39;s always good to test that what you&#39;ve got so far is working at least, and if you&#39;re seeing search results in your terminal then you&#39;re good to continue.</p>
<hr>
<h1 id="printing-the-rating-for-the-selected-title">Printing the rating for the selected title</h1>
<p>We need some more logic to request the next page and print the value from the <code>span</code> element we identified earlier. You may have noticed that in the <code>search</code> function we defined, we&#39;re returning the <code>href</code>s but we&#39;re yet to use them. Let&#39;s incorporate them now.</p>
<p>In <code>scrape.py</code>, add another function:</p>
<pre><div class="copy-me" onclick="copyCode(this)">Copy</div><code><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_rating</span>(<span class="hljs-params">href</span>):</span>
    <span class="hljs-comment"># href passed in here should be from what we found earlier, the href from the &lt;a&gt; tag that the title was wrapped in</span>
    response = requests.get(<span class="hljs-string">f&quot;https://www.imdb.com<span class="hljs-subst">{href}</span>&quot;</span>)
    html = response.text
    soup = BeautifulSoup(html, <span class="hljs-string">&quot;html.parser&quot;</span>)
    <span class="hljs-comment"># Select by CSS selector for .ratingValue class and get the first result (index 0), we only expect there to be one</span>
    rating = soup.select(<span class="hljs-string">&quot;.ratingValue&quot;</span>)[<span class="hljs-number">0</span>].span.get_text()
    <span class="hljs-keyword">return</span> rating</code></pre><p>And let&#39;s use it in our <code>run</code> function:</p>
<pre><div class="copy-me" onclick="copyCode(this)">Copy</div><code><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span>():</span>
    <span class="hljs-comment"># Main interaction</span>
    search_term = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Search IMDB: &quot;</span>)
    results = search(search_term)
    num_results = <span class="hljs-built_in">len</span>(results)

    print(<span class="hljs-string">f&quot;Found <span class="hljs-subst">{num_results}</span> results:&quot;</span>)
    <span class="hljs-keyword">for</span> i, result <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(results):
        print(<span class="hljs-string">f&quot;(<span class="hljs-subst">{i+<span class="hljs-number">1</span>}</span>) <span class="hljs-subst">{result[<span class="hljs-string">&#x27;title&#x27;</span>]}</span>&quot;</span>)

    <span class="hljs-comment"># Convert to int and subtract one to undo the addition to the index in the above loop</span>
    selection = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>(<span class="hljs-string">f&quot;Select by entering a number (1-<span class="hljs-subst">{num_results}</span>): &quot;</span>)) - <span class="hljs-number">1</span>
    selected_result = results[selection]
    <span class="hljs-comment"># Pass in the href to the title we want to get the rating for</span>
    rating = get_rating(selected_result[<span class="hljs-string">&quot;href&quot;</span>])

    print(<span class="hljs-string">f&quot;<span class="hljs-subst">{selected_result[<span class="hljs-string">&#x27;title&#x27;</span>]}</span> has a rating of <span class="hljs-subst">{rating}</span>!&quot;</span>)

<span class="hljs-comment"># Again, make sure you call this in scrape.py</span>
run()</code></pre><p>Running our app now results in the following behavior:</p>
<p><img src="/images/imdb/final.png" alt="Final output"></p>
<hr>
<h1 id="summary">Summary</h1>
<p>If you can use an API to get ahold of the data that you&#39;re after, you should always do so, it&#39;s faster and less prone to errors. Scraping the web can get messy sometimes depending on the structure of the DOM. As you may have already figured out, if something was to change on the layout of IMDB, it would potentially break our app.</p>
<p>I hope you learned something new and that you find the information provided here useful, maybe you were looking to use data from some site in your own project? Go ahead and try it out ðŸ˜Š.</p>
<p>Feel free to ask any questions.</p>
<p>Enjoy! <a href="https://github.com/simon-nystrom/simple-web-scrape">Here</a> is the associated repository for this post.</p>
</article></main><footer class="Footer__FooterWrapper-sc-1r5v4in-0 gCPmgg"><div class="Footer__Copyright-sc-1r5v4in-1 ffSMEu copyright">Simon NystrÃ¶m Â© <!-- -->2020</div><div class="Footer__Social-sc-1r5v4in-2 dlVATn"><a target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/in/simon-nystr%C3%B6m-192b12a5/" class="Footer__A-sc-1r5v4in-4 btlfRb"><div class="Footer__Icon-sc-1r5v4in-3 iZJeFu"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin-in" class="svg-inline--fa fa-linkedin-in fa-w-14 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"></path></svg></div></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/simon-nystrom/" class="Footer__A-sc-1r5v4in-4 btlfRb"><div class="Footer__Icon-sc-1r5v4in-3 iZJeFu"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" class="svg-inline--fa fa-github fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></div></a><a target="_blank" rel="noopener noreferrer" href="mailto:simon.nystrom90@gmail.com" class="Footer__A-sc-1r5v4in-4 btlfRb"><div class="Footer__Icon-sc-1r5v4in-3 iZJeFu"><svg aria-hidden="true" focusable="false" data-prefix="far" data-icon="envelope" class="svg-inline--fa fa-envelope fa-w-16 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"></path></svg></div></a><a target="_blank" rel="noopener noreferrer" href="https://dev.to/simonnystrom" class="Footer__A-sc-1r5v4in-4 btlfRb"><div class="Footer__Icon-sc-1r5v4in-3 iZJeFu"><svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="dev" class="svg-inline--fa fa-dev fa-w-14 " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M120.12 208.29c-3.88-2.9-7.77-4.35-11.65-4.35H91.03v104.47h17.45c3.88 0 7.77-1.45 11.65-4.35 3.88-2.9 5.82-7.25 5.82-13.06v-69.65c-.01-5.8-1.96-10.16-5.83-13.06zM404.1 32H43.9C19.7 32 .06 51.59 0 75.8v360.4C.06 460.41 19.7 480 43.9 480h360.2c24.21 0 43.84-19.59 43.9-43.8V75.8c-.06-24.21-19.7-43.8-43.9-43.8zM154.2 291.19c0 18.81-11.61 47.31-48.36 47.25h-46.4V172.98h47.38c35.44 0 47.36 28.46 47.37 47.28l.01 70.93zm100.68-88.66H201.6v38.42h32.57v29.57H201.6v38.41h53.29v29.57h-62.18c-11.16.29-20.44-8.53-20.72-19.69V193.7c-.27-11.15 8.56-20.41 19.71-20.69h63.19l-.01 29.52zm103.64 115.29c-13.2 30.75-36.85 24.63-47.44 0l-38.53-144.8h32.57l29.71 113.72 29.57-113.72h32.58l-38.46 144.8z"></path></svg></div></a></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"html":"\u003cp\u003eSometimes you want to access data on the web that isn\u0026#39;t easily available through an API. For that, web scraping is a viable alternative. Web scraping is in essence a way to programmatically visit a web site as if you were a browser and fetch the data that way. This tutorial post will guide you through the process of web scraping using Python3, and two libraries \u003ca href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\"\u003eBeautifulSoup\u003c/a\u003e and \u003ca href=\"https://requests.readthedocs.io/en/master/\"\u003eRequests\u003c/a\u003e. As an example, we will build a command line application to search and print ratings for movies and TV shows on IMDB.\u003c/p\u003e\n\u003chr\u003e\n\u003ch1 id=\"project-setup\"\u003eProject setup\u003c/h1\u003e\n\u003cp\u003eTo follow along with the tutorial you will need to have the following:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.python.org/downloads/\"\u003ePython\u003c/a\u003e installed\u003c/li\u003e\n\u003cli\u003eSome basic knowledge of Python and some basic HTML/CSS knowledge\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAlternatively you can check out \u003ca href=\"https://newcurrent.se/blog/containerized-development-environment\"\u003emy blog post for using dev containers\u003c/a\u003e and follow that guide but select the \u003ccode\u003ePython 3\u003c/code\u003e container spec when creating the dev container. If you can\u0026#39;t get the dev container way to work, you can refer to the \u003ca href=\"https://github.com/simon-nystrom/simple-web-scrape\"\u003erepository for this blog post\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eLet\u0026#39;s begin by creating a folder for our project and installing the required dependencies:\u003c/p\u003e\n\u003cpre\u003e\u003cdiv class=\"copy-me\" onclick=\"copyCode(this)\"\u003eCopy\u003c/div\u003e\u003ccode\u003emkdir web-scrape\n\u003cspan class=\"hljs-built_in\"\u003ecd\u003c/span\u003e web-scrape\npip3 install beautifulsoup4 requests\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ebeautifulsoup4\u003c/code\u003e lets us easily access DOM elements programmatically\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erequests\u003c/code\u003e gives us a nice and easy to use interface to make HTTP requests\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch1 id=\"researching-the-applications-lifecycle\"\u003eResearching the application\u0026#39;s lifecycle\u003c/h1\u003e\n\u003cp\u003eAs stated in the introduction, we\u0026#39;re going to focus on searching on IMDB showing the rating for some selected title. Our first step should be to do these steps in a browser and see what it looks like there.\u003c/p\u003e\n\u003cp\u003eVisit \u003ca href=\"http://www.imdb.com\"\u003ewww.imdb.com\u003c/a\u003e in your browser and search for a movie of your choice. I searched for \u003cem\u003eJurassic Park\u003c/em\u003e, you should be greeted with something like the following image:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/imdb/jurassic_park_search_res.png\" alt=\"Jurassic Park search result on IMDB\"\u003e\u003c/p\u003e\n\u003cp\u003eOnce you\u0026#39;re on this page, inspect one of the rows in the \u003cem\u003e\u0026quot;Titles\u0026quot;\u003c/em\u003e table by right clicking and pressing \u003cem\u003e\u0026quot;Inspect element\u0026quot;\u003c/em\u003e, this varies from browser to browser but in Firefox it looks like this:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/imdb/inspect_element.png\" alt=\"Inspect element\"\u003e\u003c/p\u003e\n\u003cp\u003eYou might also have noticed that something opened up at the bottom of your browser, that section is commonly referred to as the dev tools. We\u0026#39;ll be using that now to figure out the structure of the data that we\u0026#39;re after. At the time of writing this, it looks like this:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/imdb/dev_tools.png\" alt=\"Dev tools open\"\u003e\u003c/p\u003e\n\u003cp\u003eWhat\u0026#39;s displayed here is the \u003ca href=\"https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model/Introduction\"\u003eDOM\u003c/a\u003e structure. The highlighted row here is what I selected when taking the \u003cem\u003e\u0026quot;Inspect element\u0026quot;\u003c/em\u003e action earlier. This shows us how all the HTML nodes relate to each other and where in the DOM the data we\u0026#39;re after is located. Since we want to be able to list these results in our application, we need to be able to present these search results.\u003c/p\u003e\n\u003cp\u003eWe can see that the data we\u0026#39;re interested in is located inside the \u003ccode\u003e\u0026lt;td\u0026gt;\u003c/code\u003e element with the class \u003ccode\u003eresult_text\u003c/code\u003e, the name of the title is wrapped in an \u003ccode\u003e\u0026lt;a\u0026gt;\u003c/code\u003e element with the \u003ccode\u003ehref\u003c/code\u003e holding the relative link to the title. This is all the data we need from this page.\u003c/p\u003e\n\u003cp\u003eLet\u0026#39;s follow the link to this title to see what the next page we need to tackle looks like, click the link to one of the search results and you should end up on the page for the movie/show you picked:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/imdb/jurassic_park.png\" alt=\"Jurassic park\"\u003e\u003c/p\u003e\n\u003cp\u003eWhen on this page, let\u0026#39;s repeat the step and \u003cem\u003e\u0026quot;Inspect element\u0026quot;\u003c/em\u003e on the rating display:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/imdb/inspect_element_2.png\" alt=\"Inspect rating element\"\u003e\n\u003cimg src=\"/images/imdb/dev_tools_2.png\" alt=\"Dev tools on inspect rating element\"\u003e\u003c/p\u003e\n\u003cp\u003eHere we can see that for this page the data we\u0026#39;re interested in is located inside a \u003ccode\u003espan\u003c/code\u003e element wrapped by a \u003ccode\u003estrong\u003c/code\u003e element that is in turn wrapped by a \u003ccode\u003ediv\u003c/code\u003e element with the class \u003ccode\u003eratingValue\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eNow that we have gathered all the information we need for our app, let\u0026#39;s proceed to the coding part.\u003c/p\u003e\n\u003chr\u003e\n\u003ch1 id=\"searching-on-imdb-and-listing-the-titles\"\u003eSearching on IMDB and listing the titles\u003c/h1\u003e\n\u003cp\u003eCreate a file \u003ccode\u003escrape.py\u003c/code\u003e, this will be our only file for this project. In it we will begin by importing the required dependencies and adding search functionality:\u003c/p\u003e\n\u003cpre\u003e\u003cdiv class=\"copy-me\" onclick=\"copyCode(this)\"\u003eCopy\u003c/div\u003e\u003ccode\u003e\u003cspan class=\"hljs-comment\"\u003e# scrape.py\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e requests\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e bs4 \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e BeautifulSoup\n\n\u003cspan class=\"hljs-function\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title\"\u003esearch\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003esearch_term\u003c/span\u003e):\u003c/span\u003e\n    \u003cspan class=\"hljs-comment\"\u003e# Make the search request to IMDB\u003c/span\u003e\n    response = requests.get(\u003cspan class=\"hljs-string\"\u003ef\u0026quot;https://www.imdb.com/find?q=\u003cspan class=\"hljs-subst\"\u003e{search_term}\u003c/span\u003e\u0026quot;\u003c/span\u003e)\n    html = response.text\n    soup = BeautifulSoup(html, \u003cspan class=\"hljs-string\"\u003e\u0026quot;html.parser\u0026quot;\u003c/span\u003e)\n    \u003cspan class=\"hljs-comment\"\u003e# Find the table with the class findList\u003c/span\u003e\n    table = soup.find(\u003cspan class=\"hljs-string\"\u003e\u0026quot;table\u0026quot;\u003c/span\u003e, {\u003cspan class=\"hljs-string\"\u003e\u0026quot;class\u0026quot;\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\u0026quot;findList\u0026quot;\u003c/span\u003e})\n    \u003cspan class=\"hljs-comment\"\u003e# Use CSS selector syntax to get all td elements from the table with the class result_text\u003c/span\u003e\n    rows = table.select(\u003cspan class=\"hljs-string\"\u003e\u0026quot;tr td.result_text\u0026quot;\u003c/span\u003e)\n    \u003cspan class=\"hljs-comment\"\u003e# Construct a list with the search results, store the title and the href in dicts\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e [{\u003cspan class=\"hljs-string\"\u003e\u0026quot;title\u0026quot;\u003c/span\u003e: row.get_text().strip(), \u003cspan class=\"hljs-string\"\u003e\u0026quot;href\u0026quot;\u003c/span\u003e: row.a[\u003cspan class=\"hljs-string\"\u003e\u0026#x27;href\u0026#x27;\u003c/span\u003e]} \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e row \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e rows]\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eLet\u0026#39;s add another function to this file where we\u0026#39;ll place our user interaction code:\u003c/p\u003e\n\u003cpre\u003e\u003cdiv class=\"copy-me\" onclick=\"copyCode(this)\"\u003eCopy\u003c/div\u003e\u003ccode\u003e\u003cspan class=\"hljs-function\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title\"\u003erun\u003c/span\u003e():\u003c/span\u003e\n    search_term = \u003cspan class=\"hljs-built_in\"\u003einput\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\u0026quot;Search IMDB: \u0026quot;\u003c/span\u003e)\n    results = search(search_term)\n    num_results = \u003cspan class=\"hljs-built_in\"\u003elen\u003c/span\u003e(results)\n    print(\u003cspan class=\"hljs-string\"\u003ef\u0026quot;Found \u003cspan class=\"hljs-subst\"\u003e{num_results}\u003c/span\u003e results:\u0026quot;\u003c/span\u003e)\n    \u003cspan class=\"hljs-comment\"\u003e# Use built-in function enumerate to access the index variable i\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e i, result \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003eenumerate\u003c/span\u003e(results):\n        print(\u003cspan class=\"hljs-string\"\u003ef\u0026quot;(\u003cspan class=\"hljs-subst\"\u003e{i+\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e}\u003c/span\u003e) \u003cspan class=\"hljs-subst\"\u003e{result[\u003cspan class=\"hljs-string\"\u003e\u0026#x27;title\u0026#x27;\u003c/span\u003e]}\u003c/span\u003e\u0026quot;\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# Don\u0026#x27;t forget this line! We have to call the run function or nothing will happen when we run our program.\u003c/span\u003e\nrun()\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eSave the file and we\u0026#39;re ready to try our app to see what it looks like right now, run it by going to the terminal and running:\u003c/p\u003e\n\u003cpre\u003e\u003cdiv class=\"copy-me\" onclick=\"copyCode(this)\"\u003eCopy\u003c/div\u003e\u003ccode\u003epython3 scrape.py\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eEnter a search term and something similar should show up:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/imdb/in_app_search_res.png\" alt=\"in app search results\"\u003e\u003c/p\u003e\n\u003cp\u003eYou might notice that selecting a result does nothing at the moment, and that\u0026#39;s cause we only implemented half the logic. It\u0026#39;s always good to test that what you\u0026#39;ve got so far is working at least, and if you\u0026#39;re seeing search results in your terminal then you\u0026#39;re good to continue.\u003c/p\u003e\n\u003chr\u003e\n\u003ch1 id=\"printing-the-rating-for-the-selected-title\"\u003ePrinting the rating for the selected title\u003c/h1\u003e\n\u003cp\u003eWe need some more logic to request the next page and print the value from the \u003ccode\u003espan\u003c/code\u003e element we identified earlier. You may have noticed that in the \u003ccode\u003esearch\u003c/code\u003e function we defined, we\u0026#39;re returning the \u003ccode\u003ehref\u003c/code\u003es but we\u0026#39;re yet to use them. Let\u0026#39;s incorporate them now.\u003c/p\u003e\n\u003cp\u003eIn \u003ccode\u003escrape.py\u003c/code\u003e, add another function:\u003c/p\u003e\n\u003cpre\u003e\u003cdiv class=\"copy-me\" onclick=\"copyCode(this)\"\u003eCopy\u003c/div\u003e\u003ccode\u003e\u003cspan class=\"hljs-function\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title\"\u003eget_rating\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003ehref\u003c/span\u003e):\u003c/span\u003e\n    \u003cspan class=\"hljs-comment\"\u003e# href passed in here should be from what we found earlier, the href from the \u0026lt;a\u0026gt; tag that the title was wrapped in\u003c/span\u003e\n    response = requests.get(\u003cspan class=\"hljs-string\"\u003ef\u0026quot;https://www.imdb.com\u003cspan class=\"hljs-subst\"\u003e{href}\u003c/span\u003e\u0026quot;\u003c/span\u003e)\n    html = response.text\n    soup = BeautifulSoup(html, \u003cspan class=\"hljs-string\"\u003e\u0026quot;html.parser\u0026quot;\u003c/span\u003e)\n    \u003cspan class=\"hljs-comment\"\u003e# Select by CSS selector for .ratingValue class and get the first result (index 0), we only expect there to be one\u003c/span\u003e\n    rating = soup.select(\u003cspan class=\"hljs-string\"\u003e\u0026quot;.ratingValue\u0026quot;\u003c/span\u003e)[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].span.get_text()\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e rating\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAnd let\u0026#39;s use it in our \u003ccode\u003erun\u003c/code\u003e function:\u003c/p\u003e\n\u003cpre\u003e\u003cdiv class=\"copy-me\" onclick=\"copyCode(this)\"\u003eCopy\u003c/div\u003e\u003ccode\u003e\u003cspan class=\"hljs-function\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title\"\u003erun\u003c/span\u003e():\u003c/span\u003e\n    \u003cspan class=\"hljs-comment\"\u003e# Main interaction\u003c/span\u003e\n    search_term = \u003cspan class=\"hljs-built_in\"\u003einput\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\u0026quot;Search IMDB: \u0026quot;\u003c/span\u003e)\n    results = search(search_term)\n    num_results = \u003cspan class=\"hljs-built_in\"\u003elen\u003c/span\u003e(results)\n\n    print(\u003cspan class=\"hljs-string\"\u003ef\u0026quot;Found \u003cspan class=\"hljs-subst\"\u003e{num_results}\u003c/span\u003e results:\u0026quot;\u003c/span\u003e)\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e i, result \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003eenumerate\u003c/span\u003e(results):\n        print(\u003cspan class=\"hljs-string\"\u003ef\u0026quot;(\u003cspan class=\"hljs-subst\"\u003e{i+\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e}\u003c/span\u003e) \u003cspan class=\"hljs-subst\"\u003e{result[\u003cspan class=\"hljs-string\"\u003e\u0026#x27;title\u0026#x27;\u003c/span\u003e]}\u003c/span\u003e\u0026quot;\u003c/span\u003e)\n\n    \u003cspan class=\"hljs-comment\"\u003e# Convert to int and subtract one to undo the addition to the index in the above loop\u003c/span\u003e\n    selection = \u003cspan class=\"hljs-built_in\"\u003eint\u003c/span\u003e(\u003cspan class=\"hljs-built_in\"\u003einput\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef\u0026quot;Select by entering a number (1-\u003cspan class=\"hljs-subst\"\u003e{num_results}\u003c/span\u003e): \u0026quot;\u003c/span\u003e)) - \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e\n    selected_result = results[selection]\n    \u003cspan class=\"hljs-comment\"\u003e# Pass in the href to the title we want to get the rating for\u003c/span\u003e\n    rating = get_rating(selected_result[\u003cspan class=\"hljs-string\"\u003e\u0026quot;href\u0026quot;\u003c/span\u003e])\n\n    print(\u003cspan class=\"hljs-string\"\u003ef\u0026quot;\u003cspan class=\"hljs-subst\"\u003e{selected_result[\u003cspan class=\"hljs-string\"\u003e\u0026#x27;title\u0026#x27;\u003c/span\u003e]}\u003c/span\u003e has a rating of \u003cspan class=\"hljs-subst\"\u003e{rating}\u003c/span\u003e!\u0026quot;\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# Again, make sure you call this in scrape.py\u003c/span\u003e\nrun()\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eRunning our app now results in the following behavior:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/imdb/final.png\" alt=\"Final output\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch1 id=\"summary\"\u003eSummary\u003c/h1\u003e\n\u003cp\u003eIf you can use an API to get ahold of the data that you\u0026#39;re after, you should always do so, it\u0026#39;s faster and less prone to errors. Scraping the web can get messy sometimes depending on the structure of the DOM. As you may have already figured out, if something was to change on the layout of IMDB, it would potentially break our app.\u003c/p\u003e\n\u003cp\u003eI hope you learned something new and that you find the information provided here useful, maybe you were looking to use data from some site in your own project? Go ahead and try it out ðŸ˜Š.\u003c/p\u003e\n\u003cp\u003eFeel free to ask any questions.\u003c/p\u003e\n\u003cp\u003eEnjoy! \u003ca href=\"https://github.com/simon-nystrom/simple-web-scrape\"\u003eHere\u003c/a\u003e is the associated repository for this post.\u003c/p\u003e\n","date":"2020-11-01","title":"Web scraping with Python","slug":"web-scraping-python","summary":"Learn how to scrape web sites to access information programmatically using Python3, BeautifulSoup and Requests.","categories":[],"published":true,"tags":["python","web-scraping","requests","tutorial","beautifulsoup"]}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"web-scraping-python"},"buildId":"3OeNvj5yk7XHWh00j0orF","nextExport":false,"isFallback":false,"gsp":true,"head":[["meta",{"charSet":"utf-8"}],["meta",{"name":"viewport","content":"initial-scale=1.0, width=device-width"}],["title",{"children":"Web scraping with Python"}],["meta",{"name":"description","content":"Learn how to scrape web sites to access information programmatically using Python3, BeautifulSoup and Requests."}]]}</script><script nomodule="" src="/_next/static/chunks/polyfills-fa276ba060a4a8ac7eef.js"></script><script src="/_next/static/chunks/main-652e3d69fea5bda26a4d.js" async=""></script><script src="/_next/static/chunks/webpack-e067438c4cf4ef2ef178.js" async=""></script><script src="/_next/static/chunks/framework.93a4db703368d9b8f53e.js" async=""></script><script src="/_next/static/chunks/a9a7754c.c97121148934262ae49b.js" async=""></script><script src="/_next/static/chunks/99f422a92ff7083adb8a7d840734144fa7589f68.f6d970403bd2fa4c2639.js" async=""></script><script src="/_next/static/chunks/99ce5ded03d7686e4bf70ff5f951df53c1ed333a.b57b3b603baeb24450d4.js" async=""></script><script src="/_next/static/chunks/pages/_app-24c8b9694b01810a31ee.js" async=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-a9359318c29489431ba1.js" async=""></script><script src="/_next/static/3OeNvj5yk7XHWh00j0orF/_buildManifest.js" async=""></script><script src="/_next/static/3OeNvj5yk7XHWh00j0orF/_ssgManifest.js" async=""></script></body></html>